✅ PART 1 — Multiple Choice (Q1–Q10)
Q1. ARIMA — Purpose of the Integrated component (‘I’)

✔ Correct Answer:
To make the time series stationary through differencing

Q2. Purpose of k-means clustering

✔ Correct Answer:
To partition data into k clusters based on similarity

Q3. What do confounders represent in DAGs?

✔ Correct Answer:
Variables that influence both the exposure and the outcome

Q4. Specificity (TNR) of the classifier

Given the binary confusion matrix used in this assignment:

TN = 34, FP = 12
TNR = 34 / (34 + 12) = 0.739 ≈ 0.74

✔ Correct Answer: 0.74

Q5. Purpose of exponential smoothing parameter (alpha)

✔ Correct Answer:
Controls how quickly the model adapts to recent data

Q6. Purpose of an adjustment set in causal inference

✔ Correct Answers:
To identify the minimum set of variables needed to block all confounding paths

Q7. Disadvantage of lazy learners (e.g., k-NN)

✔ Correct Answer:
Performance degrades with high-dimensional data

Q8. Number of open paths in the DAG

✔ Correct Answer: 2
(The diagram contains two open backdoor paths.)

Q9. When accuracy is misleading

✔ Correct Answer:
When the dataset is highly imbalanced

Q10. Naive assumption in Naive Bayes

✔ Correct Answer:
Features are conditionally independent given the class

✅ PART 2
Q11. Outcome regression + Adjustment sets
✔ Unbiased regressions

The true confounder in the D → Y relationship is W, because:

V → W → D → Y
and W → Y

Thus, valid regressions:

Y ~ D + W (lin_YW)

FWL-Residual regression (adjusting for W)

❌ Incorrect model

Y ~ D + V (lin_YV) → V is not a confounder once W is in the model

✔ Valid Adjustment Sets

{W}

{W, V} (valid but not minimal)

Two-step OLS (FWL) coefficient on D

Here is the complete correct code:

# Step 1: residualize Y and D on W
rY <- resid(lm(Y ~ W, data = data_obs))
rD <- resid(lm(D ~ W, data = data_obs))

# Step 2: regress residualized Y on residualized D
lin_FWL <- lm(rY ~ rD)
broom::tidy(lin_FWL, conf.int = TRUE)

Q12. Spam Classification using XGBoost
(1) Train/test split, recipe, XGBoost model
set.seed(8740)

# split
splits <- initial_split(spam_data, prop = 0.8, strata = type)
train  <- training(splits)
test   <- testing(splits)

# recipe
default_recipe <- recipe(type ~ ., data = train)

# xgboost model
default_model <- 
  boost_tree(
    trees = 1000,
    mtry = 10,
    tree_depth = 5,
    learn_rate = 0.05,
    loss_reduction = 0,
    sample_size = 1
  ) %>%
  set_engine("xgboost") %>%
  set_mode("classification")

(2) Workflow → Fit → Test-set predictions
default_workflow <- 
  workflow() %>%
  add_model(default_model) %>%
  add_recipe(default_recipe)

lm_fit <- fit(default_workflow, data = train)

testing_results <- augment(lm_fit, new_data = test)

(3) ROC curve and Accuracy
✔ ROC Curve
testing_results %>%
  roc_curve(type, .pred_spam) %>%
  autoplot()

✔ Accuracy
testing_results %>%
  accuracy(type, .pred_class)

(4) Feature importance & most important feature
booster <- (lm_fit %>% extract_fit_parsnip())$fit

importance_matrix <- xgboost::xgb.importance(model = booster)
importance_matrix

✔ Most important feature:

Likely: char_freq_; (semicolon) or word_freq_free
(Exact answer depends on importances, but these are consistently #1 in the UCI dataset.)

Q13. step_lag()
(1) Purpose of step_lag()

✔ Correct Answer:
step_lag() creates lagged versions of numeric variables for time-series modeling.

(2) Example + first rows description
data <- data.frame(
  week = as.Date("2025-01-01") + 0:5,
  value = c(100, 120, 130, 125, 140, 150),
  city = "Toronto"
)

rec <- recipe(value ~ week + city, data = data) %>%
  step_lag(value, lag = 1)

lagged_data <- prep(rec) %>% bake(new_data = data)
lagged_data

✔ Description

A new column value_lag1 appears

First row: NA (no previous value)

Row 2: lag = 100

Row 3: lag = 120

Row 4: lag = 130

etc.

Q14. Causal critique of the parachute study

✔ Correct Answer:
The study cannot estimate a causal effect because:

The treatment groups do not differ on meaningful exposure (all jumps are from safe, near-zero altitude).

The outcome (death/injury) has zero probability, violating positivity.

Therefore the study provides no causal information about parachute effectiveness.
